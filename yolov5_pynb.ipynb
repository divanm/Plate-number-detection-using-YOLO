{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmraotcbO2nQ"
      },
      "source": [
        "IMPORT DATA DAN ZIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C--EPJcJcM8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsDA9hoVKvsc"
      },
      "outputs": [],
      "source": [
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HMkOxnxBh9Qx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580ddd73-d452-44ff-9394-3d21b495a644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0_q6sqFJFve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d71da08-4164-4deb-a326-1a76cf26a8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "Test = (\"/content/drive/MyDrive/DataTest.zip\")\n",
        "\n",
        "with ZipFile(Test, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT_0-m-PUy7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "53861d1d-e076-4c74-8ccd-3bd36a934810"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id Vehicleregistrationplate        NameofFile\n",
              "0      1                    A7814    DataTrain1.png\n",
              "1      2                  B1074QO    DataTrain2.png\n",
              "2      3                  B1031QO    DataTrain3.png\n",
              "3      4                  B187EDA    DataTrain4.png\n",
              "4      5                  B1089VD    DataTrain5.png\n",
              "..   ...                      ...               ...\n",
              "795  796                 B1677EJC  DataTrain796.png\n",
              "796  797                  B1743VO  DataTrain797.png\n",
              "797  798                 AD1416YD  DataTrain798.png\n",
              "798  799                 AB5419TN  DataTrain799.png\n",
              "799  800                 AB6315SE  DataTrain800.png\n",
              "\n",
              "[800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9526bdab-a5c0-4e29-9e16-fe118e220e23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Vehicleregistrationplate</th>\n",
              "      <th>NameofFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A7814</td>\n",
              "      <td>DataTrain1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B1074QO</td>\n",
              "      <td>DataTrain2.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B1031QO</td>\n",
              "      <td>DataTrain3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B187EDA</td>\n",
              "      <td>DataTrain4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B1089VD</td>\n",
              "      <td>DataTrain5.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>796</td>\n",
              "      <td>B1677EJC</td>\n",
              "      <td>DataTrain796.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>797</td>\n",
              "      <td>B1743VO</td>\n",
              "      <td>DataTrain797.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>798</td>\n",
              "      <td>AD1416YD</td>\n",
              "      <td>DataTrain798.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>799</td>\n",
              "      <td>AB5419TN</td>\n",
              "      <td>DataTrain799.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>800</td>\n",
              "      <td>AB6315SE</td>\n",
              "      <td>DataTrain800.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9526bdab-a5c0-4e29-9e16-fe118e220e23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9526bdab-a5c0-4e29-9e16-fe118e220e23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9526bdab-a5c0-4e29-9e16-fe118e220e23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "df = pd.read_csv('/content/drive/MyDrive/datatrainfix.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "Train = (\"/content/drive/MyDrive/DataTrain.zip\")\n",
        "\n",
        "with ZipFile(Train, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUk56hps32UR",
        "outputId": "cc651c95-51f0-4c5f-ce9b-15f170335710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsZ2gnc_LF95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8444a991-a281-41f4-caee-d765b89d65c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "label = (\"/content/drive/MyDrive/labels.zip\")\n",
        "\n",
        "with ZipFile(label, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI0_vUByOY54"
      },
      "source": [
        "SPLIT DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0kpvcBV4rxz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "input_folder = (\"/content/Data Train\")\n",
        "train_folder = (\"/content/databaru/train/images\")\n",
        "val_folder = (\"/content/databaru/test/images\")\n",
        "split_ratio = 0.8  # Rasio pembagian data (misalnya 0.8 berarti 80% set latihan, 20% set validasi)\n",
        "\n",
        "# Mendapatkan daftar file dalam folder input\n",
        "file_list = os.listdir(input_folder)\n",
        "random.shuffle(file_list)  # Mengacak urutan file\n",
        "\n",
        "# Menghitung jumlah file untuk setiap set\n",
        "num_files = len(file_list)\n",
        "num_train = int(num_files * split_ratio)\n",
        "num_val = num_files - num_train\n",
        "\n",
        "# Membuat folder set latihan dan set validasi jika belum ada\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(val_folder, exist_ok=True)\n",
        "\n",
        "# Memindahkan file ke set latihan\n",
        "for file_name in file_list[:num_train]:\n",
        "    src_path = os.path.join(input_folder, file_name)\n",
        "    dst_path = os.path.join(train_folder, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Memindahkan file ke set validasi\n",
        "for file_name in file_list[num_train:]:\n",
        "    src_path = os.path.join(input_folder, file_name)\n",
        "    dst_path = os.path.join(val_folder, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pq8mqHwOLHCI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "input_labels = (\"/content/labels\")\n",
        "train_labels = (\"/content/databaru/train/labels\")\n",
        "val_labels = (\"/content/databaru/test/labels\")\n",
        "split_ratio = 0.8  # Rasio pembagian data (misalnya 0.8 berarti 80% set latihan, 20% set validasi)\n",
        "\n",
        "# Mendapatkan daftar file dalam folder input\n",
        "file_list = os.listdir(input_labels)\n",
        "random.shuffle(file_list)  # Mengacak urutan file\n",
        "\n",
        "# Menghitung jumlah file untuk setiap set\n",
        "num_files = len(file_list)\n",
        "num_train = int(num_files * split_ratio)\n",
        "num_val = num_files - num_train\n",
        "\n",
        "# Membuat folder set latihan dan set validasi jika belum ada\n",
        "os.makedirs(train_labels, exist_ok=True)\n",
        "os.makedirs(val_labels, exist_ok=True)\n",
        "\n",
        "# Memindahkan file ke set latihan\n",
        "for file_name in file_list[:num_train]:\n",
        "    src_path = os.path.join(input_labels, file_name)\n",
        "    dst_path = os.path.join(train_labels, file_name)\n",
        "    shutil.copy(src_path, dst_path)\n",
        "\n",
        "# Memindahkan file ke set validasi\n",
        "for file_name in file_list[num_train:]:\n",
        "    src_path = os.path.join(input_labels, file_name)\n",
        "    dst_path = os.path.join(val_labels, file_name)\n",
        "    shutil.copy(src_path, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train yolov8"
      ],
      "metadata": {
        "id": "eySDelyYb_1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4sqCUkZcOkT",
        "outputId": "b5867067-0e58-4aca-b833-38833cbea0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15814, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 15814 (delta 9), reused 23 (delta 2), pack-reused 15768\u001b[K\n",
            "Receiving objects: 100% (15814/15814), 14.64 MiB | 9.58 MiB/s, done.\n",
            "Resolving deltas: 100% (10821/10821), done.\n",
            "/content/yolov5\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m625.9/625.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "data = dict(\n",
        "    train= ('/content/databaru/train/images'),\n",
        "    val= ('/content/databaru/test/images'),\n",
        "    nc = 36,\n",
        "    names = ['A','B','C','D','E','F','G','H','I','J','K',\n",
        "             'L','M','N','O','P','Q','R','S','T','U','V','W','X','Y',\n",
        "             'Z','0','1','2','3','4','5','6','7','8','9']\n",
        ")\n",
        "\n",
        "# Mengonversi data ke format YAML\n",
        "yaml_content = yaml.dump(data)\n",
        "\n",
        "# Menyimpan konten YAML ke dalam file\n",
        "with open('data.yaml', 'w') as file:\n",
        "    file.write(yaml_content)\n",
        "\n",
        "print(\"File YAML telah berhasil dibuat.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSyrBj7Vf5p2",
        "outputId": "03a33b90-7c8e-4003-d8b0-7b0d90d454bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File YAML telah berhasil dibuat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil\n",
        "\n",
        "import torch\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "def free_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "free_gpu_cache()"
      ],
      "metadata": {
        "id": "GUYrkimKDObn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --cfg models/yolov5s.yaml --batch-size 64 --name Model --epochs 300"
      ],
      "metadata": {
        "id": "n7lrczgPDahC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TO PREDICT IMAGES IN A FOLDER ##\n",
        "!python detect.py --source '/content/DataTest/Data Test for BDC 2023 - Penyisihan' --weights '/content/drive/MyDrive/runs/train/Model/weights/best.pt' --save-txt"
      ],
      "metadata": {
        "id": "MoO9PkIvqbJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b12b5a-be23-4a16-e4b2-c5e290388b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/runs/train/Model/weights/best.pt'], source=/content/DataTest/Data Test for BDC 2023 - Penyisihan, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-193-g485da42 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "image 1/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest1.png: 224x640 1 A, 1 D, 1 E, 1 O, 2 0s, 1 3, 1 4, 1 7, 39.6ms\n",
            "image 2/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest10.png: 256x640 2 Bs, 1 H, 1 Y, 1 1, 1 3, 1 6, 1 7, 56.3ms\n",
            "image 3/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest100.png: 192x640 1 B, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8, 40.7ms\n",
            "image 4/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest11.png: 224x640 2 Bs, 1 E, 1 V, 2 1s, 1 3, 1 6, 1 7, 6.1ms\n",
            "image 5/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest12.png: 224x640 1 B, 1 M, 1 N, 2 Ws, 1 Z, 1 1, 1 6, 1 7, 1 8, 6.0ms\n",
            "image 6/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest13.png: 224x640 1 A, 1 D, 2 Ss, 1 1, 2 3s, 1 9, 6.0ms\n",
            "image 7/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest14.png: 224x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 6.0ms\n",
            "image 8/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest15.png: 352x640 1 B, 1 S, 1 T, 1 Z, 1 0, 2 1s, 1 8, 42.2ms\n",
            "image 9/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest16.png: 288x640 1 B, 1 J, 1 S, 1 T, 1 1, 2 4s, 1 7, 39.9ms\n",
            "image 10/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest17.png: 224x640 1 P, 1 U, 6.1ms\n",
            "image 11/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest18.png: 224x640 1 B, 3 Ts, 1 Z, 1 0, 1 1, 1 2, 1 6, 6.0ms\n",
            "image 12/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest19.png: 224x640 1 B, 1 J, 1 O, 1 T, 1 1, 1 3, 1 6, 2 7s, 6.2ms\n",
            "image 13/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest2.png: 224x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 6.4ms\n",
            "image 14/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest20.png: 192x640 (no detections), 5.7ms\n",
            "image 15/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest21.png: 352x640 1 A, 1 B, 3 3s, 1 5, 1 6, 7.6ms\n",
            "image 16/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest22.png: 224x640 1 B, 1 M, 1 N, 1 P, 1 Z, 1 1, 1 2, 1 3, 1 6, 6.1ms\n",
            "image 17/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest23.png: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 5.7ms\n",
            "image 18/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest24.png: 256x640 1 B, 1 J, 1 K, 1 T, 1 1, 6.4ms\n",
            "image 19/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest25.png: 160x640 2 As, 1 D, 1 O, 1 0, 1 4, 1 7, 1 8, 48.1ms\n",
            "image 20/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest26.png: 352x640 1 B, 1 E, 1 G, 1 K, 3 1s, 1 3, 7.6ms\n",
            "image 21/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest27.png: 192x640 1 B, 1 N, 1 0, 1 1, 1 3, 1 7, 6.6ms\n",
            "image 22/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest28.png: 192x640 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6, 5.7ms\n",
            "image 23/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest29.png: 192x640 1 A, 1 B, 1 C, 3 Os, 2 Qs, 1 0, 1 2, 5.7ms\n",
            "image 24/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest3.png: 256x640 1 B, 1 T, 1 1, 6.4ms\n",
            "image 25/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest30.png: 320x640 1 A, 1 M, 1 Z, 2 1s, 1 2, 2 9s, 39.8ms\n",
            "image 26/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest31.png: 224x640 1 B, 1 K, 1 T, 1 X, 2 0s, 2 1s, 1 2, 6.2ms\n",
            "image 27/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest32.png: 224x640 1 B, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6, 6.0ms\n",
            "image 28/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest33.png: 192x640 1 B, 1 J, 1 T, 1 U, 1 0, 1 1, 1 3, 1 9, 5.7ms\n",
            "image 29/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest34.png: 352x640 1 A, 1 B, 1 0, 2 1s, 1 2, 7.6ms\n",
            "image 30/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest35.png: 256x640 1 B, 1 E, 1 F, 1 T, 1 0, 1 1, 1 6, 1 8, 6.4ms\n",
            "image 31/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest36.png: 416x640 1 A, 1 F, 1 S, 1 4, 1 6, 1 7, 1 9, 40.5ms\n",
            "image 32/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest37.png: 224x640 1 B, 1 F, 1 N, 1 O, 1 1, 1 5, 2 6s, 6.1ms\n",
            "image 33/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest38.png: 288x640 1 B, 1 J, 1 Q, 1 S, 1 0, 1 1, 1 3, 1 6, 7.7ms\n",
            "image 34/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest39.png: 192x640 1 B, 1 F, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5, 5.7ms\n",
            "image 35/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest4.png: 192x640 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s, 5.7ms\n",
            "image 36/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest40.png: 224x640 1 B, 1 C, 1 J, 1 T, 1 Y, 1 0, 1 1, 1 3, 1 6, 1 8, 8.8ms\n",
            "image 37/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest41.png: 352x640 1 A, 1 B, 1 H, 1 U, 1 2, 1 3, 1 4, 1 9, 7.7ms\n",
            "image 38/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest42.png: 160x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9, 7.2ms\n",
            "image 39/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest43.png: 160x640 1 B, 1 L, 1 T, 1 1, 1 3, 1 7, 1 9, 8.3ms\n",
            "image 40/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest44.png: 256x640 1 B, 1 0, 1 1, 2 2s, 7.8ms\n",
            "image 41/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest45.png: 224x640 1 B, 1 M, 1 T, 1 Z, 1 0, 2 1s, 1 2, 1 6, 9.4ms\n",
            "image 42/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest46.png: 288x640 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7, 8.1ms\n",
            "image 43/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest47.png: 192x640 1 B, 1 I, 1 S, 1 V, 1 0, 2 1s, 1 2, 7.3ms\n",
            "image 44/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest48.png: 224x640 1 A, 1 D, 1 E, 1 O, 1 Q, 1 0, 1 3, 1 4, 1 7, 7.1ms\n",
            "image 45/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest49.png: 352x640 1 A, 1 B, 1 C, 1 X, 1 2, 1 3, 1 4, 1 5, 9.2ms\n",
            "image 46/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest5.png: 384x640 1 A, 1 B, 1 D, 1 2, 1 3, 1 4, 2 7s, 65.2ms\n",
            "image 47/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest50.png: 224x640 2 Bs, 1 E, 1 J, 2 1s, 1 5, 1 8, 1 9, 8.6ms\n",
            "image 48/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest51.png: 256x640 (no detections), 7.3ms\n",
            "image 49/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest52.png: 256x640 1 B, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9, 6.8ms\n",
            "image 50/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest53.png: 256x640 1 B, 1 E, 1 F, 1 O, 1 1, 1 6, 1 8, 1 9, 7.7ms\n",
            "image 51/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest54.png: 192x640 1 B, 1 K, 1 V, 2 1s, 1 3, 1 7, 7.6ms\n",
            "image 52/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest55.png: 352x640 1 B, 1 N, 1 P, 1 S, 1 W, 1 1, 1 3, 1 6, 7.7ms\n",
            "image 53/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest56.png: 192x640 1 B, 1 K, 1 T, 2 Zs, 2 1s, 2 6s, 7.2ms\n",
            "image 54/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest57.png: 192x640 2 As, 1 V, 1 0, 1 1, 1 4, 1 8, 6.6ms\n",
            "image 55/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest58.png: 192x640 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8, 7.5ms\n",
            "image 56/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest59.png: 160x640 1 B, 1 D, 1 L, 1 0, 1 1, 2 2s, 1 8, 8.6ms\n",
            "image 57/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest6.png: 192x640 2 Bs, 2 Ns, 1 V, 1 1, 1 2, 2 7s, 7.4ms\n",
            "image 58/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest60.png: 224x640 2 Bs, 1 H, 1 K, 1 1, 2 2s, 1 4, 7.3ms\n",
            "image 59/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest61.png: 320x640 2 As, 1 B, 1 X, 1 2, 1 5, 1 7, 1 8, 8.1ms\n",
            "image 60/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest62.png: 288x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 7.7ms\n",
            "image 61/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest63.png: 288x640 (no detections), 7.6ms\n",
            "image 62/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest64.png: 224x640 1 B, 1 F, 1 Q, 1 R, 2 1s, 1 2, 2 3s, 7.5ms\n",
            "image 63/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest65.png: 192x640 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3, 8.0ms\n",
            "image 64/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest66.png: 256x640 1 A, 1 D, 1 J, 1 R, 2 9s, 7.3ms\n",
            "image 65/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest67.png: 288x640 1 B, 1 E, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8, 7.7ms\n",
            "image 66/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest68.png: 256x640 2 As, 1 Q, 1 T, 2 0s, 1 4, 1 7, 7.2ms\n",
            "image 67/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest69.png: 160x640 1 B, 2 Ss, 1 W, 3 1s, 1 2, 1 4, 7.3ms\n",
            "image 68/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest7.png: 288x640 (no detections), 7.9ms\n",
            "image 69/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest70.png: 256x640 1 B, 2 Js, 1 T, 1 1, 1 2, 1 3, 1 6, 9.6ms\n",
            "image 70/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest71.png: 256x640 1 B, 1 E, 1 L, 1 R, 1 7, 8.7ms\n",
            "image 71/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest72.png: 192x640 1 B, 1 J, 1 Q, 1 T, 2 1s, 1 5, 1 8, 7.4ms\n",
            "image 72/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest73.png: 288x640 1 B, 1 J, 1 N, 1 U, 1 1, 1 3, 1 4, 1 7, 7.7ms\n",
            "image 73/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest74.png: 192x640 1 B, 1 E, 1 F, 1 Y, 1 1, 1 3, 1 4, 1 7, 10.8ms\n",
            "image 74/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest75.png: 160x640 1 B, 1 O, 1 Q, 1 0, 2 1s, 1 5, 1 7, 7.1ms\n",
            "image 75/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest76.png: 352x640 2 As, 1 H, 2 Ws, 1 Y, 1 2, 2 3s, 1 9, 7.6ms\n",
            "image 76/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest77.png: 192x640 1 B, 1 J, 2 Ts, 1 1, 1 2, 1 3, 1 5, 7.2ms\n",
            "image 77/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest78.png: 256x640 1 B, 1 L, 2 Ss, 2 1s, 1 5, 1 7, 7.1ms\n",
            "image 78/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest79.png: 192x640 1 B, 1 K, 1 V, 2 1s, 1 3, 1 7, 7.9ms\n",
            "image 79/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest8.png: 160x640 1 B, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9, 7.2ms\n",
            "image 80/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest80.png: 224x640 1 B, 1 J, 1 S, 1 T, 2 1s, 1 3, 1 6, 7.1ms\n",
            "image 81/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest81.png: 192x640 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9, 7.5ms\n",
            "image 82/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest82.png: 384x640 1 B, 1 K, 1 N, 1 Y, 1 1, 1 2, 1 3, 1 5, 8.1ms\n",
            "image 83/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest83.png: 192x640 1 B, 2 Us, 1 Y, 2 0s, 1 1, 1 8, 7.1ms\n",
            "image 84/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest84.png: 192x640 1 B, 1 E, 1 T, 2 Vs, 3 1s, 1 4, 6.7ms\n",
            "image 85/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest85.png: 352x640 1 B, 1 E, 1 K, 1 3, 3 7s, 1 8, 7.7ms\n",
            "image 86/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest86.png: 256x640 1 B, 1 D, 1 F, 1 R, 1 1, 2 3s, 1 9, 7.2ms\n",
            "image 87/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest87.png: 192x640 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 3, 1 9, 7.4ms\n",
            "image 88/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest88.png: 320x640 1 A, 1 B, 1 D, 1 H, 1 2, 1 5, 1 8, 1 9, 11.0ms\n",
            "image 89/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest89.png: 256x640 1 A, 1 D, 1 U, 1 1, 1 4, 1 8, 7.2ms\n",
            "image 90/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest9.png: 256x640 1 B, 1 0, 1 1, 1 2, 1 7, 6.7ms\n",
            "image 91/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest90.png: 224x640 1 B, 1 L, 1 P, 1 T, 1 1, 1 5, 2 8s, 7.2ms\n",
            "image 92/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest91.png: 256x640 1 B, 1 N, 2 Ss, 1 1, 1 3, 1 4, 1 6, 7.4ms\n",
            "image 93/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest92.png: 288x640 1 A, 1 B, 1 H, 1 O, 2 1s, 1 3, 1 5, 8.0ms\n",
            "image 94/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest93.png: 288x640 (no detections), 7.7ms\n",
            "image 95/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest94.png: 224x640 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8, 7.1ms\n",
            "image 96/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest95.png: 160x640 2 Bs, 1 R, 1 U, 2 1s, 1 6, 1 9, 7.2ms\n",
            "image 97/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest96.png: 256x640 1 U, 1 1, 1 2, 1 5, 1 8, 7.5ms\n",
            "image 98/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest97.png: 192x640 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8, 9.5ms\n",
            "image 99/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest98.png: 192x640 1 A, 1 E, 1 G, 6.7ms\n",
            "image 100/100 /content/DataTest/Data Test for BDC 2023 - Penyisihan/DataTest99.png: 160x640 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9, 7.2ms\n",
            "Speed: 0.3ms pre-process, 10.8ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "95 labels saved to runs/detect/exp/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "def process_image(DataTest):\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=\"/content/drive/MyDrive/runs/train/Model/weights/best.pt\")\n",
        "    results = model(DataTest)\n",
        "    results.print()\n",
        "\n",
        "    pd_box = results.pandas().xyxy[0]\n",
        "    pd_box = pd_box.sort_values('xmin')\n",
        "\n",
        "    pd_box['selisih'] = pd_box['xmax'] - pd_box['xmin']\n",
        "    s_rata = pd_box['selisih'].mean()\n",
        "\n",
        "    s = []\n",
        "    for i in range(1, len(pd_box)):\n",
        "        kurang = pd_box['xmax'].iloc[i-1] - pd_box['xmin'].iloc[i]\n",
        "        s.append(kurang)\n",
        "    pd_box['s'] = [None] + s\n",
        "\n",
        "    baris = len(pd_box)\n",
        "    baris_dihapus = []\n",
        "\n",
        "    for i in range(1, baris):\n",
        "        if pd_box['s'].iloc[i] <= 0:\n",
        "            continue\n",
        "        elif pd_box['s'].iloc[i] > 0:\n",
        "            cek = pd_box['s'].iloc[i] / s_rata\n",
        "            if cek >= 0.5:\n",
        "                if pd_box['confidence'].iloc[i] <= pd_box['confidence'].iloc[i-1]:\n",
        "                     baris_dihapus.append(i)\n",
        "                elif pd_box['confidence'].iloc[i] > pd_box['confidence'].iloc[i-1]:\n",
        "                    baris_dihapus.append(i-1)\n",
        "            elif cek < 0.5:\n",
        "                continue\n",
        "\n",
        "    pd_box = pd_box.drop(pd_box.index[baris_dihapus])\n",
        "    return pd_box['name'].tolist()\n",
        "\n",
        "# Membuat dictionary dengan key berupa nama gambar dan value berupa hasil looping\n",
        "result_dict = {}\n",
        "for i in range(1, 101):\n",
        "    image_path = f'/content/DataTest/Penyisihan/DataTest{i}.png'  # Ganti dengan path dan format nama gambar yang sesuai\n",
        "    processed_data = process_image(image_path)\n",
        "    result_dict[f'DataTest{i}'] = processed_data\n",
        "\n",
        "# Membuat DataFrame dari dictionary\n",
        "result_df = pd.DataFrame(result_dict.items(), columns=['File Gambar', 'List Name'])\n",
        "\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJC7FXglTYSy",
        "outputId": "fc6541da-c43e-4c78-85a0-1a5420280c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 112x358 1 A, 1 D, 1 E, 1 O, 2 0s, 1 3, 1 4, 1 7\n",
            "Speed: 2.9ms pre-process, 6.1ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 98x318 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9\n",
            "Speed: 2.4ms pre-process, 6.2ms inference, 1.3ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 100x282 1 B, 1 T, 1 1\n",
            "Speed: 2.8ms pre-process, 6.4ms inference, 1.3ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 106x416 1 B, 1 K, 1 T, 1 Z, 2 1s, 2 6s\n",
            "Speed: 2.8ms pre-process, 6.3ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 43x72 1 A, 1 B, 1 D, 1 2, 1 3, 1 4, 2 7s\n",
            "Speed: 1.8ms pre-process, 8.1ms inference, 2.5ms NMS per image at shape (1, 3, 384, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 94x352 2 Bs, 2 Ns, 1 V, 1 1, 1 2, 2 7s\n",
            "Speed: 3.6ms pre-process, 8.9ms inference, 1.8ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 148x342 (no detections)\n",
            "Speed: 4.4ms pre-process, 8.1ms inference, 0.6ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 90x372 1 B, 1 J, 1 T, 1 W, 1 1, 1 3, 1 5, 1 9\n",
            "Speed: 4.9ms pre-process, 7.9ms inference, 1.7ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 170x482 1 B, 1 0, 1 1, 1 2, 1 7\n",
            "Speed: 7.2ms pre-process, 8.1ms inference, 1.7ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 21x54 2 Bs, 1 H, 1 Y, 1 1, 1 3, 1 6, 1 7\n",
            "Speed: 3.6ms pre-process, 7.9ms inference, 1.7ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 15x46 2 Bs, 1 E, 1 V, 2 1s, 1 3, 1 6, 1 7\n",
            "Speed: 1.3ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 154x458 1 B, 1 M, 1 N, 2 Ws, 1 Z, 1 1, 1 6, 1 7, 1 8\n",
            "Speed: 4.1ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 152x442 1 A, 1 D, 2 Ss, 1 1, 2 3s, 1 9\n",
            "Speed: 5.1ms pre-process, 9.2ms inference, 6.9ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 88x284 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6\n",
            "Speed: 3.8ms pre-process, 6.7ms inference, 1.5ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 108x210 1 B, 1 S, 1 T, 1 Z, 1 0, 2 1s, 1 8\n",
            "Speed: 2.4ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 104x258 1 B, 1 J, 1 S, 1 T, 1 1, 2 4s, 1 7\n",
            "Speed: 2.7ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 162x494 1 P, 1 U\n",
            "Speed: 3.8ms pre-process, 6.1ms inference, 1.6ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 21x68 1 B, 3 Ts, 1 Z, 1 0, 1 1, 1 2, 1 6\n",
            "Speed: 1.4ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 102x322 1 B, 1 J, 1 O, 1 T, 1 1, 1 3, 1 6, 2 7s\n",
            "Speed: 3.2ms pre-process, 6.1ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 104x412 (no detections)\n",
            "Speed: 3.2ms pre-process, 6.4ms inference, 0.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 37x72 1 A, 1 B, 3 3s, 1 5, 1 6\n",
            "Speed: 1.8ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 16x50 1 B, 1 M, 1 N, 1 P, 1 Z, 1 1, 1 2, 1 3, 1 6\n",
            "Speed: 1.8ms pre-process, 9.0ms inference, 1.5ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 86x318 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8\n",
            "Speed: 2.4ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 46x130 1 B, 1 J, 1 K, 1 T, 1 1\n",
            "Speed: 2.1ms pre-process, 10.2ms inference, 2.1ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 138x634 2 As, 1 D, 1 O, 1 0, 1 4, 1 7, 1 8\n",
            "Speed: 4.8ms pre-process, 6.0ms inference, 1.3ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 102x198 1 B, 1 E, 1 G, 1 K, 3 1s, 1 3\n",
            "Speed: 2.7ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 96x374 1 B, 1 N, 1 0, 1 1, 1 3, 1 7\n",
            "Speed: 2.5ms pre-process, 5.9ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 88x294 1 B, 1 L, 1 U, 1 0, 1 1, 1 3, 1 6\n",
            "Speed: 2.3ms pre-process, 6.2ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 176x650 1 A, 1 B, 1 C, 3 Os, 2 Qs, 1 0, 1 2\n",
            "Speed: 5.4ms pre-process, 5.8ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 140x292 1 A, 1 M, 1 Z, 2 1s, 1 2, 2 9s\n",
            "Speed: 3.9ms pre-process, 7.5ms inference, 1.3ms NMS per image at shape (1, 3, 320, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 116x350 1 B, 1 K, 1 T, 1 X, 2 0s, 2 1s, 1 2\n",
            "Speed: 3.7ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 152x474 1 B, 1 O, 1 R, 1 T, 1 1, 1 3, 1 4, 1 6\n",
            "Speed: 3.7ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 124x428 1 B, 1 J, 1 T, 1 U, 1 0, 1 1, 1 3, 1 9\n",
            "Speed: 2.9ms pre-process, 6.0ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 43x85 1 A, 1 B, 1 0, 2 1s, 1 2\n",
            "Speed: 2.2ms pre-process, 10.9ms inference, 1.7ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 158x413 1 B, 1 E, 1 F, 1 T, 1 0, 1 1, 1 6, 1 8\n",
            "Speed: 5.8ms pre-process, 8.6ms inference, 2.0ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 56x87 1 A, 1 F, 1 S, 1 4, 1 6, 1 7, 1 9\n",
            "Speed: 2.5ms pre-process, 9.0ms inference, 1.7ms NMS per image at shape (1, 3, 416, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 25x80 1 B, 1 F, 1 N, 1 O, 1 1, 1 5, 2 6s\n",
            "Speed: 2.0ms pre-process, 7.9ms inference, 1.7ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 130x310 1 B, 1 J, 1 Q, 1 S, 1 0, 1 1, 1 3, 1 6\n",
            "Speed: 4.0ms pre-process, 8.8ms inference, 1.7ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 132x444 1 B, 1 F, 1 T, 1 X, 1 1, 1 2, 1 4, 1 5\n",
            "Speed: 4.4ms pre-process, 10.7ms inference, 2.0ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 14x45 1 B, 1 C, 1 J, 1 T, 1 Y, 1 0, 1 1, 1 3, 1 6, 1 8\n",
            "Speed: 1.7ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 51x95 1 A, 1 B, 1 H, 1 U, 1 2, 1 3, 1 4, 1 9\n",
            "Speed: 1.7ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 98x396 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9\n",
            "Speed: 2.9ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 106x430 1 B, 1 L, 1 T, 1 1, 1 3, 1 7, 1 9\n",
            "Speed: 3.2ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 164x420 1 B, 1 0, 1 1, 2 2s\n",
            "Speed: 4.0ms pre-process, 6.4ms inference, 1.3ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 162x490 1 B, 1 M, 1 T, 1 Z, 1 0, 2 1s, 1 2, 1 6\n",
            "Speed: 4.1ms pre-process, 6.9ms inference, 1.7ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 216x514 1 B, 1 P, 1 W, 1 Y, 1 1, 1 2, 1 4, 1 7\n",
            "Speed: 5.0ms pre-process, 7.7ms inference, 1.6ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 86x324 1 B, 1 I, 1 S, 1 V, 1 0, 2 1s, 1 2\n",
            "Speed: 2.7ms pre-process, 5.8ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 126x388 1 A, 1 D, 1 E, 1 O, 1 Q, 1 0, 1 3, 1 4, 1 7\n",
            "Speed: 3.7ms pre-process, 6.2ms inference, 1.5ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 58x111 1 A, 1 B, 1 C, 1 X, 1 2, 1 3, 1 4, 1 5\n",
            "Speed: 1.9ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 130x394 2 Bs, 1 E, 1 J, 2 1s, 1 5, 1 8, 1 9\n",
            "Speed: 4.5ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 130x332 (no detections)\n",
            "Speed: 3.9ms pre-process, 6.4ms inference, 0.5ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 384x967 1 B, 1 F, 1 R, 1 S, 1 1, 1 4, 1 5, 1 9\n",
            "Speed: 11.1ms pre-process, 6.4ms inference, 1.4ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 138x360 1 B, 1 E, 1 F, 1 O, 1 1, 1 6, 1 8, 1 9\n",
            "Speed: 4.0ms pre-process, 6.4ms inference, 1.4ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 96x346 1 B, 1 K, 1 V, 2 1s, 1 3, 1 7\n",
            "Speed: 2.2ms pre-process, 5.8ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 291x572 1 B, 1 N, 1 P, 1 S, 1 W, 1 1, 1 3, 1 6\n",
            "Speed: 9.7ms pre-process, 7.7ms inference, 1.3ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 108x418 1 B, 1 K, 1 T, 2 Zs, 2 1s, 2 6s\n",
            "Speed: 2.7ms pre-process, 6.3ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 94x372 2 As, 1 V, 1 0, 1 1, 1 4, 1 8\n",
            "Speed: 2.8ms pre-process, 6.6ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 102x406 1 B, 1 U, 1 Y, 1 1, 1 3, 1 7, 1 8\n",
            "Speed: 2.6ms pre-process, 6.2ms inference, 1.4ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 90x396 1 B, 1 D, 1 L, 1 0, 1 1, 2 2s, 1 8\n",
            "Speed: 3.5ms pre-process, 8.1ms inference, 1.4ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 92x276 2 Bs, 1 H, 1 K, 1 1, 2 2s, 1 4\n",
            "Speed: 2.1ms pre-process, 6.1ms inference, 1.4ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 45x94 2 As, 1 B, 1 X, 1 2, 1 5, 1 7, 1 8\n",
            "Speed: 1.7ms pre-process, 7.5ms inference, 1.4ms NMS per image at shape (1, 3, 320, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 47x114 1 A, 1 D, 1 U, 1 1, 1 4, 1 8\n",
            "Speed: 1.9ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 99x232 (no detections)\n",
            "Speed: 3.2ms pre-process, 8.2ms inference, 0.5ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 102x318 1 B, 1 F, 1 Q, 1 R, 2 1s, 1 2, 2 3s\n",
            "Speed: 3.2ms pre-process, 8.0ms inference, 2.0ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 94x344 1 B, 1 I, 1 N, 1 0, 2 1s, 1 3\n",
            "Speed: 3.7ms pre-process, 9.3ms inference, 1.9ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 26x74 1 A, 1 D, 1 J, 1 R, 2 9s\n",
            "Speed: 1.7ms pre-process, 11.3ms inference, 1.8ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 29x65 1 B, 1 E, 1 S, 1 Y, 1 1, 1 3, 1 6, 1 8\n",
            "Speed: 2.0ms pre-process, 10.6ms inference, 2.0ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 136x380 2 As, 1 Q, 1 T, 2 0s, 1 4, 1 7\n",
            "Speed: 3.4ms pre-process, 7.2ms inference, 1.6ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 90x402 1 B, 2 Ss, 1 W, 3 1s, 1 2, 1 4\n",
            "Speed: 2.5ms pre-process, 6.3ms inference, 1.4ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 128x340 1 B, 2 Js, 1 T, 1 1, 1 2, 1 3, 1 6\n",
            "Speed: 2.7ms pre-process, 6.4ms inference, 1.4ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 94x244 1 B, 1 E, 1 L, 1 R, 1 7\n",
            "Speed: 3.6ms pre-process, 6.4ms inference, 1.4ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 130x438 1 B, 1 J, 1 Q, 1 T, 2 1s, 1 5, 1 8\n",
            "Speed: 3.0ms pre-process, 6.1ms inference, 1.5ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 43x100 1 B, 1 J, 1 N, 1 U, 1 1, 1 3, 1 4, 1 7\n",
            "Speed: 1.6ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 180x624 1 B, 1 E, 1 F, 1 Y, 1 1, 1 3, 1 4, 1 7\n",
            "Speed: 5.1ms pre-process, 7.2ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 96x436 1 B, 1 O, 1 Q, 1 0, 2 1s, 1 5, 1 7\n",
            "Speed: 3.3ms pre-process, 6.3ms inference, 1.4ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 36x68 2 As, 1 H, 2 Ws, 1 Y, 1 2, 2 3s, 1 9\n",
            "Speed: 1.6ms pre-process, 7.7ms inference, 1.3ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 34x121 1 B, 1 J, 2 Ts, 1 1, 1 2, 1 3, 1 5\n",
            "Speed: 2.3ms pre-process, 6.0ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 19x50 1 B, 1 L, 2 Ss, 2 1s, 1 5, 1 7\n",
            "Speed: 1.3ms pre-process, 6.4ms inference, 1.4ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 96x346 1 B, 1 K, 1 V, 2 1s, 1 3, 1 7\n",
            "Speed: 2.2ms pre-process, 5.9ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 136x416 1 B, 1 J, 1 S, 1 T, 2 1s, 1 3, 1 6\n",
            "Speed: 3.3ms pre-process, 6.1ms inference, 1.5ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 94x328 1 A, 1 E, 1 X, 1 3, 2 8s, 1 9\n",
            "Speed: 2.5ms pre-process, 8.3ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 116x198 1 B, 1 K, 1 N, 1 Y, 1 1, 1 2, 1 3, 1 5\n",
            "Speed: 3.8ms pre-process, 8.1ms inference, 1.4ms NMS per image at shape (1, 3, 384, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 15x54 1 B, 2 Us, 1 Y, 2 0s, 1 1, 1 8\n",
            "Speed: 1.9ms pre-process, 6.8ms inference, 1.5ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 98x340 1 B, 1 E, 1 T, 2 Vs, 3 1s, 1 4\n",
            "Speed: 2.8ms pre-process, 6.1ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 55x105 1 B, 1 E, 1 K, 1 3, 3 7s, 1 8\n",
            "Speed: 2.9ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 352, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 16x43 1 B, 1 D, 1 F, 1 R, 1 1, 2 3s, 1 9\n",
            "Speed: 1.7ms pre-process, 8.1ms inference, 1.8ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 33x110 1 B, 1 D, 1 F, 1 R, 1 0, 1 1, 1 3, 1 9\n",
            "Speed: 2.6ms pre-process, 5.9ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 32x67 1 A, 1 B, 1 D, 1 H, 1 2, 1 5, 1 8, 1 9\n",
            "Speed: 2.0ms pre-process, 7.9ms inference, 1.4ms NMS per image at shape (1, 3, 320, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 45x114 1 A, 1 D, 1 U, 1 1, 1 4, 1 8\n",
            "Speed: 2.3ms pre-process, 9.3ms inference, 1.7ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 124x386 1 B, 1 L, 1 P, 1 T, 1 1, 1 5, 2 8s\n",
            "Speed: 3.9ms pre-process, 8.7ms inference, 3.9ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 47x124 1 B, 1 N, 2 Ss, 1 1, 1 3, 1 4, 1 6\n",
            "Speed: 2.1ms pre-process, 8.0ms inference, 1.8ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 57x128 1 A, 1 B, 1 H, 1 O, 2 1s, 1 3, 1 5\n",
            "Speed: 2.3ms pre-process, 8.9ms inference, 1.7ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 234x524 (no detections)\n",
            "Speed: 8.8ms pre-process, 8.3ms inference, 0.6ms NMS per image at shape (1, 3, 288, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 144x418 1 B, 1 J, 1 T, 1 V, 1 0, 1 1, 1 2, 1 8\n",
            "Speed: 6.4ms pre-process, 8.4ms inference, 1.8ms NMS per image at shape (1, 3, 224, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 18x72 2 Bs, 1 R, 1 U, 2 1s, 1 6, 1 9\n",
            "Speed: 1.5ms pre-process, 9.4ms inference, 2.0ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 106x272 1 U, 1 1, 1 2, 1 5, 1 8\n",
            "Speed: 3.4ms pre-process, 8.4ms inference, 1.4ms NMS per image at shape (1, 3, 256, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 150x570 1 A, 1 B, 1 K, 1 P, 2 4s, 1 6, 1 8\n",
            "Speed: 5.0ms pre-process, 5.9ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 25x93 1 A, 1 E, 1 G\n",
            "Speed: 1.7ms pre-process, 6.7ms inference, 1.3ms NMS per image at shape (1, 3, 192, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 98x396 1 B, 1 N, 1 U, 1 0, 1 1, 1 5, 1 9\n",
            "Speed: 2.9ms pre-process, 6.1ms inference, 1.4ms NMS per image at shape (1, 3, 160, 640)\n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7107217 parameters, 0 gradients, 16.1 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 96x370 1 B, 1 R, 1 X, 1 0, 1 1, 1 4, 1 8\n",
            "Speed: 2.8ms pre-process, 6.1ms inference, 1.4ms NMS per image at shape (1, 3, 192, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    File Gambar                 List Name\n",
            "0     DataTest1  [A, D, 7, 0, 3, 4, O, E]\n",
            "1     DataTest2     [A, 9, 3, 8, 8, E, X]\n",
            "2     DataTest3                 [B, 1, T]\n",
            "3     DataTest4  [B, 1, 6, 6, 1, T, K, Z]\n",
            "4     DataTest5  [A, D, 3, 7, 7, 2, 4, B]\n",
            "..          ...                       ...\n",
            "95   DataTest96           [1, 2, 8, 5, U]\n",
            "96   DataTest97  [A, B, 8, 6, 4, 4, P, K]\n",
            "97   DataTest98                 [A, E, G]\n",
            "98   DataTest99     [B, 1, 5, 0, 9, U, N]\n",
            "99  DataTest100     [B, 1, 4, 0, 8, R, X]\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengkonversi float menjadi list\n",
        "result_df['List Name'] = result_df['List Name'].apply(lambda x: x if isinstance(x, list) else [x])\n",
        "\n",
        "# Menghapus tanda kutip dan tanda koma, dan menyisakan karakter saja\n",
        "result_df['List Name'] = result_df['List Name'].apply(lambda x: [str(name).replace('\"', '').strip() for name in x])\n",
        "\n",
        "# Menyimpan DataFrame ke dalam file CSV\n",
        "file_path = '/content/submissiomlagi.csv'  # Path file CSV yang akan disimpan\n",
        "result_df.to_csv(file_path, index=False)\n",
        "\n",
        "# Menampilkan nama file hasil.csv\n",
        "print(\"File CSV telah disimpan sebagai hasil.csv\")"
      ],
      "metadata": {
        "id": "Yt92RyAa6YPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac915c3-f848-4a80-d92c-1f96910907f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File CSV telah disimpan sebagai hasil.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengkonversi float menjadi list\n",
        "result_df['List Name'] = result_df['List Name'].apply(lambda x: x if isinstance(x, list) else [x])\n",
        "\n",
        "# Menghapus tanda kutip dan tanda koma, dan menyisakan karakter saja\n",
        "result_df['List Name'] = result_df['List Name'].apply(lambda x: [str(name).replace('\"', '').strip() for name in x])\n",
        "\n",
        "# Menampilkan nama file hasil.csv\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6THWNGB0_JfV",
        "outputId": "438604da-6d19-4516-e467-206a3e456f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    File Gambar                 List Name\n",
              "0     DataTest1  [A, D, 7, 0, 3, 4, O, E]\n",
              "1     DataTest2     [A, 9, 3, 8, 8, E, X]\n",
              "2     DataTest3                 [B, 1, T]\n",
              "3     DataTest4  [B, 1, 6, 6, 1, T, K, Z]\n",
              "4     DataTest5  [A, D, 3, 7, 7, 2, 4, B]\n",
              "..          ...                       ...\n",
              "95   DataTest96           [1, 2, 8, 5, U]\n",
              "96   DataTest97  [A, B, 8, 6, 4, 4, P, K]\n",
              "97   DataTest98                 [A, E, G]\n",
              "98   DataTest99     [B, 1, 5, 0, 9, U, N]\n",
              "99  DataTest100     [B, 1, 4, 0, 8, R, X]\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa38151b-cd5a-4d7f-9206-9abd3e27546f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Gambar</th>\n",
              "      <th>List Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DataTest1</td>\n",
              "      <td>[A, D, 7, 0, 3, 4, O, E]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DataTest2</td>\n",
              "      <td>[A, 9, 3, 8, 8, E, X]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DataTest3</td>\n",
              "      <td>[B, 1, T]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DataTest4</td>\n",
              "      <td>[B, 1, 6, 6, 1, T, K, Z]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DataTest5</td>\n",
              "      <td>[A, D, 3, 7, 7, 2, 4, B]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>DataTest96</td>\n",
              "      <td>[1, 2, 8, 5, U]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>DataTest97</td>\n",
              "      <td>[A, B, 8, 6, 4, 4, P, K]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>DataTest98</td>\n",
              "      <td>[A, E, G]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>DataTest99</td>\n",
              "      <td>[B, 1, 5, 0, 9, U, N]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>DataTest100</td>\n",
              "      <td>[B, 1, 4, 0, 8, R, X]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa38151b-cd5a-4d7f-9206-9abd3e27546f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa38151b-cd5a-4d7f-9206-9abd3e27546f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa38151b-cd5a-4d7f-9206-9abd3e27546f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#menyatukan kolom list name\n",
        "result_df['List Name'] = result_df['List Name'].astype(str).str.replace(' ', '').str.replace('[', '').str.replace(',', '').str.replace(\"'\", '').str.replace(']', '')\n",
        "#menambahkan kolom nomor\n",
        "nomor = list(range(100))\n",
        "result_df.insert(0,'', nomor)\n",
        "#menambahkan .png tiap baris file gambar\n",
        "result_df['File Gambar'] = result_df['File Gambar'] + '.png'\n",
        "#rename nama kolom sesuai format\n",
        "result_df = result_df.rename(columns={'File Gambar' : 'Name of File', 'List Name': 'Vehicleregistrationplatebymodel'})\n",
        "#menampilkan dataframe\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "8JrkzcEV_O4N",
        "outputId": "580a8218-94c1-4534-b279-b905aec1f932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-650908dd0148>:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  result_df['List Name'] = result_df['List Name'].astype(str).str.replace(' ', '').str.replace('[', '').str.replace(',', '').str.replace(\"'\", '').str.replace(']', '')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Name of File Vehicleregistrationplatebymodel\n",
              "0    0    DataTest1.png                        AD7034OE\n",
              "1    1    DataTest2.png                         A9388EX\n",
              "2    2    DataTest3.png                             B1T\n",
              "3    3    DataTest4.png                        B1661TKZ\n",
              "4    4    DataTest5.png                        AD37724B\n",
              "..  ..              ...                             ...\n",
              "95  95   DataTest96.png                           1285U\n",
              "96  96   DataTest97.png                        AB8644PK\n",
              "97  97   DataTest98.png                             AEG\n",
              "98  98   DataTest99.png                         B1509UN\n",
              "99  99  DataTest100.png                         B1408RX\n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbde185f-9a29-46aa-8079-35abd9846789\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Name of File</th>\n",
              "      <th>Vehicleregistrationplatebymodel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>DataTest1.png</td>\n",
              "      <td>AD7034OE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>DataTest2.png</td>\n",
              "      <td>A9388EX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>DataTest3.png</td>\n",
              "      <td>B1T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>DataTest4.png</td>\n",
              "      <td>B1661TKZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>DataTest5.png</td>\n",
              "      <td>AD37724B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>DataTest96.png</td>\n",
              "      <td>1285U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>DataTest97.png</td>\n",
              "      <td>AB8644PK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>DataTest98.png</td>\n",
              "      <td>AEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>DataTest99.png</td>\n",
              "      <td>B1509UN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>DataTest100.png</td>\n",
              "      <td>B1408RX</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbde185f-9a29-46aa-8079-35abd9846789')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbde185f-9a29-46aa-8079-35abd9846789 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbde185f-9a29-46aa-8079-35abd9846789');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan DataFrame ke dalam file CSV\n",
        "file_path = '/content/submissionlago.csv'  # Path file CSV yang akan disimpan\n",
        "result_df.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "QiGPKb_ZcMVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def akurasi(test, prediksi):\n",
        "  tt = test.ljust(9)\n",
        "  pp = prediksi.ljust(9)\n",
        "  r = [1 if x==y else 0 for (x,y) in zip(tt,pp)]\n",
        "  s = sum(r)\n",
        "  return s/9"
      ],
      "metadata": {
        "id": "wZWaxeG5_T8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataplat = pd.read_csv(\"/content/drive/MyDrive/dataplat.csv\")\n",
        "dataplat['Prediksi'] = result_df['Vehicleregistrationplatebymodel']\n",
        "file_path = '/content/datayolov5baru.csv'\n",
        "dataplat.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "id": "vZJKEEKw_ZUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 100):\n",
        "  hasil_akurasi = akurasi(dataplat['Plat Sebenarnya'].iloc[i], dataplat['Prediksi'].iloc[i])\n",
        "hasil_akurasi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "pSLOSdxQ_bTO",
        "outputId": "8c0bc6a2-b462-4ba3-f748-6a70472a5016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a49642841743>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mhasil_akurasi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0makurasi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataplat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Plat Sebenarnya'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataplat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediksi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhasil_akurasi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-b3681b1293dc>\u001b[0m in \u001b[0;36makurasi\u001b[0;34m(test, prediksi)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediksi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ZipFile' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "for i in range(0, 100):\n",
        "  hasil_akurasi = akurasi(dataplat['Plat Sebenarnya'].iloc[i], dataplat['Prediksi'].iloc[i])\n",
        "  total = total + hasil_akurasi\n",
        "akurasi_semuanya = total/100\n",
        "akurasi_semuanya"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "4MKqRy60_dGU",
        "outputId": "e58beee5-95a8-4bdb-ac9a-5995a34f9ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-9a0610ab99f9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mhasil_akurasi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0makurasi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataplat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Plat Sebenarnya'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataplat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prediksi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhasil_akurasi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0makurasi_semuanya\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-b3681b1293dc>\u001b[0m in \u001b[0;36makurasi\u001b[0;34m(test, prediksi)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediksi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mljust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ZipFile' object is not callable"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}